{
  "llama_path": "/path/to/llama.cpp/main",
  "model_path": "/path/to/llama.cpp/models/ggml-vic13b-q4_0.bin",
  "llama_params": [
    "--color",
    "-f",
    "./prompts/alpaca.txt",
    "--ctx_size", "2048", 
    "-n", "-1", 
    "-ins", "-b", "256",
    "--top_k", "10000",
    "--temp", "0.2", 
    "--repeat_penalty", "1.1", 
    "-t", "7"
  ],
  "port": 8080
}