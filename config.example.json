{
  "llama_path": "/path/to/llama.cpp/main",
  "model_path": "/path/to/llama.cpp/models/Meta-Llama-3-8B-Instruct.Q2_K.gguf",
  "llama_params": [
    "--color",
    "--ctx_size", "1024",
    "-n", "-1",
    "-ins", "-b", "256",
    "--top_k", "500",
    "--temp", "0.5",
    "--repeat_penalty","1.7",
    "-t", "7"
  ],
  "port": 8080
}
